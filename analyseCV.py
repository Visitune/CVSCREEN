import streamlit as st
import PyPDF2
import json
from datetime import datetime
from pathlib import Path
import groq
import pandas as pd
import plotly.graph_objects as go
import hashlib

st.set_page_config(page_title="Analyse de CV GFSI", layout="wide")
st.title("üìÑ Analyse comparative de CV - Auditeurs GFSI")

def jauge(titre, valeur):
    fig = go.Figure(go.Indicator(mode="gauge+number", value=valeur * 100, domain={'x': [0, 1], 'y': [0, 1]}, title={'text': titre}, gauge={'axis': {'range': [0, 100]}, 'bar': {'color': "green" if valeur >= 0.75 else "orange" if valeur >= 0.5 else "red"}, 'steps': [{'range': [0, 50], 'color': "#f8d7da"}, {'range': [50, 75], 'color': "#fff3cd"}, {'range': [75, 100], 'color': "#d4edda"}]}))
    fig.update_layout(height=300)
    st.plotly_chart(fig, use_container_width=True)

def extract_json_strict(text):
    s = text.strip()
    a = s.find("{")
    b = s.rfind("}")
    if a == -1 or b == -1 or b <= a:
        return None
    try:
        return json.loads(s[a:b+1])
    except Exception:
        pass
    stack, start = 0, None
    for i, ch in enumerate(s):
        if ch == "{":
            if stack == 0:
                start = i
            stack += 1
        elif ch == "}":
            stack -= 1
            if stack == 0 and start is not None:
                try:
                    return json.loads(s[start:i+1])
                except Exception:
                    continue
    return None

def validate_analysis(obj):
    if not isinstance(obj, dict):
        return False, "Objet racine non valide"
    if "analysis" not in obj or not isinstance(obj["analysis"], list):
        return False, "Champ 'analysis' manquant"
    ok_items = []
    for it in obj["analysis"]:
        if not isinstance(it, dict):
            continue
        need = ["exigence_id", "exigence_titre", "statut", "justification", "confiance", "ponderation", "niveau_requis"]
        if not all(k in it for k in need):
            continue
        it["statut"] = str(it["statut"]).upper().replace("√Ä", "A")
        if "category_id" not in it:
            it["category_id"] = ""
        ok_items.append(it)
    obj["analysis"] = ok_items
    if "score_global" not in obj:
        obj["score_global"] = 0
    if "synthese" not in obj:
        obj["synthese"] = ""
    return True, obj

def create_example_referential():
    return {
        "metadata": {"name": "GFSI - Auditeur Senior", "version": "1.0", "description": "R√©f√©rentiel pour auditeurs seniors GFSI", "date_creation": "2024-01-01"},
        "categories": {
            "formation": {"name": "Formation et Certification", "weight": 0.3, "description": "Formations acad√©miques et certifications professionnelles"},
            "experience": {"name": "Exp√©rience Professionnelle", "weight": 0.4, "description": "Exp√©rience pratique en audit et s√©curit√© alimentaire"},
            "competences": {"name": "Comp√©tences Techniques", "weight": 0.2, "description": "Ma√Ætrise des standards et outils d'audit"},
            "langues": {"name": "Comp√©tences Linguistiques", "weight": 0.1, "description": "Capacit√©s de communication internationale"}
        },
        "exigences": {
            "FORM_001": {"id": "FORM_001", "category": "formation", "title": "Formation sup√©rieure en s√©curit√© alimentaire", "description": "Dipl√¥me Bac+5 minimum en sciences alimentaires, microbiologie, ou √©quivalent", "criteres": ["Dipl√¥me universitaire niveau Master (Bac+5) minimum", "Sp√©cialisation en s√©curit√© alimentaire, microbiologie, ou domaine connexe", "Formation continue en normes GFSI"], "exemples_conformes": ["Master en Sciences Alimentaires - Universit√© de Lyon", "Ing√©nieur Agronome sp√©cialit√© S√©curit√© Alimentaire - AgroParisTech", "PhD en Microbiologie Alimentaire + formations GFSI"], "exemples_non_conformes": ["BTS Agroalimentaire uniquement", "Licence en biologie sans sp√©cialisation", "Formation courte en audit sans dipl√¥me sup√©rieur"], "niveau_requis": "obligatoire", "ponderation": 1.0},
            "EXP_001": {"id": "EXP_001", "category": "experience", "title": "Exp√©rience minimum en audit GFSI", "description": "Au moins 5 ans d'exp√©rience en audit de syst√®mes de management s√©curit√© alimentaire", "criteres": ["Minimum 5 ann√©es d'exp√©rience en audit", "Exp√©rience dans au moins 2 standards GFSI diff√©rents", "Participation √† minimum 50 audits document√©s"], "exemples_conformes": ["7 ans d'exp√©rience - Lead Auditor BRC et IFS", "Auditeur senior FSSC 22000 - 120 audits r√©alis√©s", "10 ans audit SQF + formations continues"], "exemples_non_conformes": ["3 ans d'exp√©rience uniquement en qualit√©", "Exp√©rience audit ISO 9001 sans s√©curit√© alimentaire", "Formation th√©orique sans pratique terrain"], "niveau_requis": "obligatoire", "ponderation": 1.0},
            "COMP_001": {"id": "COMP_001", "category": "competences", "title": "Ma√Ætrise des standards GFSI", "description": "Connaissance approfondie d'au moins 2 standards GFSI reconnus", "criteres": ["Certification dans au moins 2 standards GFSI", "Connaissance des √©volutions r√©glementaires", "Capacit√© √† interpr√©ter les non-conformit√©s"], "exemples_conformes": ["Certifi√© Lead Auditor BRC + IFS", "Expert FSSC 22000 + SQF Level 2", "Formateur agr√©√© standards GFSI"], "exemples_non_conformes": ["Connaissance th√©orique uniquement", "Certification dans un seul standard", "Pas de mise √† jour des certifications"], "niveau_requis": "recommande", "ponderation": 0.8},
            "LANG_001": {"id": "LANG_001", "category": "langues", "title": "Comp√©tences linguistiques internationales", "description": "Ma√Ætrise de l'anglais professionnel + une langue additionnelle", "criteres": ["Anglais professionnel niveau C1 minimum", "Capacit√© √† r√©diger des rapports d'audit en anglais", "Une langue europ√©enne additionnelle appr√©ci√©e"], "exemples_conformes": ["Anglais courant + Allemand interm√©diaire", "Bilingue fran√ßais/anglais + notions espagnol", "Certifications TOEIC 900+ ou √©quivalent"], "exemples_non_conformes": ["Anglais scolaire uniquement", "Pas de pratique professionnelle de l'anglais", "Monolingue fran√ßais"], "niveau_requis": "souhaitable", "ponderation": 0.6}
        }
    }

with st.sidebar:
    st.header("üîß Configuration")
    api_key = st.text_input("üîë Cl√© API Groq :", type="password")
    if st.button("üìù Cr√©er un r√©f√©rentiel d'exemple"):
        ref_dir = Path("referentiels")
        ref_dir.mkdir(exist_ok=True)
        with open(ref_dir / "exemple_auditeur_senior.json", "w", encoding="utf-8") as f:
            json.dump(create_example_referential(), f, indent=2, ensure_ascii=False)
        st.success("‚úÖ R√©f√©rentiel d'exemple cr√©√© dans /referentiels/")
    if not api_key:
        st.warning("Veuillez saisir une cl√© API valide.")
        st.stop()
    client = groq.Client(api_key=api_key)

    @st.cache_data
    def load_referentials():
        out = {}
        ref_dir = Path("referentiels")
        if ref_dir.exists():
            for file in ref_dir.glob("*.json"):
                try:
                    with open(file, encoding="utf-8") as f:
                        data = json.load(f)
                    if "exigences" in data or "categories" in data:
                        out[file.stem] = data
                    else:
                        st.warning(f"‚ö†Ô∏è Structure invalide pour {file.name}")
                except Exception as e:
                    st.error(f"‚ùå Erreur lecture {file.name}: {e}")
        return out

    referentials = load_referentials()
    if not referentials:
        st.error("Aucun r√©f√©rentiel valide trouv√©.")
        st.info("‚Ä¢ Cliquez sur 'üìù Cr√©er un r√©f√©rentiel d'exemple' pour commencer")
        st.stop()

    ref_name = st.selectbox("üìö R√©f√©rentiel GFSI :", list(referentials.keys()))
    selected_ref = referentials[ref_name]

    if "metadata" in selected_ref:
        md = selected_ref["metadata"]
        st.info(f"**{md.get('name', 'Sans nom')}**\n\n{md.get('description', '')}")
        st.caption(f"Version: {md.get('version', 'N/A')} | Date: {md.get('date_creation', md.get('last_updated', 'N/A'))}")

    model = st.selectbox("üß† Mod√®le IA :", ["llama3-8b-8192", "llama-3.3-70b-versatile", "llama-3.1-8b-instant"])

def build_prompt(selected_ref, cv_text):
    if "categories" in selected_ref and any(isinstance(v, dict) and "subcategories" in v for v in selected_ref["categories"].values()):
        lines = []
        for cat_name, cat_data in selected_ref["categories"].items():
            lines.append(f"\n=== CATEGORIE: {cat_name} (Poids: {cat_data.get('weight', 0)}) ===")
            lines.append(cat_data.get("description", ""))
            for sub_name, sub in cat_data.get("subcategories", {}).items():
                lines.append(f"\n-- Sous-cat√©gorie: {sub_name} (Poids: {sub.get('weight', 0)}) --")
                for req in sub.get("requirements", []):
                    rid = req.get("id", "N/A")
                    txt = req.get("text", "")
                    minacc = req.get("minimum_acceptable", "")
                    refs = ", ".join(req.get("references", []))
                    exs = req.get("examples", [])
                    ex_block = "\n".join(["‚Ä¢ " + e for e in exs]) if exs else ""
                    lines.append(f"EXIGENCE {rid}\nTexte: {txt}\nMinimum acceptable: {minacc}\nR√©f√©rences: {refs}\nExemples:\n{ex_block}\n---")
        exigences_detail = "\n".join(lines)
    else:
        lines = []
        for req_id, req in selected_ref.get("exigences", {}).items():
            lines.append(f"EXIGENCE {req_id}: {req.get('title','')}\nDescription: {req.get('description','')}\nNiveau: {req.get('niveau_requis','')}\nPond√©ration: {req.get('ponderation',1.0)}\nCrit√®res:\n" + "\n".join(["‚Ä¢ "+c for c in req.get("criteres", [])]))
            lines.append("Exemples conformes:\n" + "\n".join(["‚Ä¢ "+e for e in req.get("exemples_conformes", [])]))
            lines.append("Exemples non conformes:\n" + "\n".join(["‚Ä¢ "+e for e in req.get("exemples_non_conformes", [])]) + "\n---")
        exigences_detail = "\n".join(lines)
    schema = {
        "analysis": [{
            "exigence_id": "ID requis exact",
            "exigence_titre": "Titre",
            "category_id": "ID cat√©gorie ou sous-cat√©gorie",
            "statut": "CONFORME | A CHALLENGER | NON CONFORME",
            "justification": "Preuves et raisonnement",
            "elements_cv": "Citations du CV",
            "confiance": 0.0,
            "niveau_requis": "obligatoire|recommande|souhaitable",
            "ponderation": 1.0
        }],
        "score_global": 0.0,
        "synthese": "R√©sum√© et recommandations"
    }
    return f"""
Tu es un expert conformit√© GFSI.
Analyse le CV par rapport aux exigences list√©es ci-dessous.
M√©thode: d√©tecte les √©l√©ments du CV, compare aux crit√®res, statue, justifie, et note la confiance.
R√©pond UNIQUEMENT avec un JSON strictement valide correspondant EXACTEMENT au sch√©ma suivant:
{json.dumps(schema, ensure_ascii=False, indent=2)}

R√âF√âRENTIEL:
{exigences_detail}

CV:
{cv_text}
"""

@st.cache_data
def pdf_to_text(file_bytes):
    reader = PyPDF2.PdfReader(file_bytes)
    return " ".join([page.extract_text() or "" for page in reader.pages])

def file_digest(uploaded_file):
    uploaded_file.seek(0)
    data = uploaded_file.read()
    uploaded_file.seek(0)
    return hashlib.sha256(data).hexdigest(), data

uploaded_files = st.file_uploader("üìÑ Chargez un ou plusieurs CV (PDF uniquement)", type=["pdf"], accept_multiple_files=True)

if uploaded_files and st.button("üîç Lancer l'analyse IA"):
    results_all, details_export = [], []
    with st.spinner("Analyse des CV en cours..."):
        for up in uploaded_files:
            try:
                digest, data = file_digest(up)
                cv_text = pdf_to_text(data)
                prompt = build_prompt(selected_ref, cv_text)
                response = client.chat.completions.create(model=model, messages=[{"role": "user", "content": prompt}], temperature=0.1, max_tokens=4000)
                raw = response.choices[0].message.content or ""
                parsed = extract_json_strict(raw)
                if not parsed:
                    st.error(f"JSON invalide pour {up.name}")
                    continue
                ok, res = validate_analysis(parsed)
                if not ok:
                    st.error(f"{res} pour {up.name}")
                    continue
                analysis = res["analysis"]
                for a in analysis:
                    a["cv"] = up.name
                    details_export.append(a)
                score_pondere = 0.0
                poids_total = 0.0
                conformes = challengers = non_conformes = 0
                for item in analysis:
                    statut = item.get("statut", "")
                    ponderation = float(item.get("ponderation", 1.0) or 1.0)
                    confiance = float(item.get("confiance", 0) or 0)
                    if statut == "CONFORME":
                        conformes += 1
                        score_pondere += confiance * ponderation
                    elif statut == "A CHALLENGER":
                        challengers += 1
                        score_pondere += (confiance * 0.5) * ponderation
                    else:
                        non_conformes += 1
                    poids_total += ponderation
                score_final = (score_pondere / poids_total) if poids_total > 0 else 0.0
                results_all.append({"nom": up.name, "conformes": conformes, "challengers": challengers, "non_conformes": non_conformes, "score": round(score_final, 2), "score_global": res.get("score_global", score_final), "details": analysis, "synthese": res.get("synthese", "")})
            except Exception as e:
                st.error(f"‚ùå Erreur pour {up.name} : {e}")

    if results_all:
        st.subheader("üìä Comparaison des candidats")
        comparison_df = pd.DataFrame([{"Candidat": r["nom"], "Score Global": f"{r['score']:.0%}", "‚úÖ Conformes": r["conformes"], "‚ö†Ô∏è √Ä challenger": r["challengers"], "‚ùå Non conformes": r["non_conformes"]} for r in results_all])
        st.dataframe(comparison_df, use_container_width=True)

        for result in results_all:
            st.subheader(f"üìÑ Analyse d√©taill√©e : {result['nom']}")
            col1, col2 = st.columns([1, 2])
            with col1:
                jauge("Score Global", result["score"])
            with col2:
                st.markdown("### üß† Synth√®se IA")
                st.info(result["synthese"])

            df = pd.DataFrame(result["details"])
            st.markdown("### üìã Analyse par cat√©gorie")
            if "category_id" in df.columns and df["category_id"].astype(str).str.len().gt(0).any():
                for cat in sorted(df["category_id"].fillna("").unique()):
                    if cat == "":
                        continue
                    subset = df[df["category_id"] == cat]
                    if subset.empty:
                        continue
                    with st.expander(f"{cat} ({len(subset)})"):
                        for _, row in subset.iterrows():
                            status_emoji = {"CONFORME": "‚úÖ", "A CHALLENGER": "‚ö†Ô∏è", "NON CONFORME": "‚ùå"}
                            emoji = status_emoji.get(row["statut"], "‚ùì")
                            st.write(f"{emoji} **{row['exigence_titre']}**")
                            st.write(f"*Justification:* {row['justification']}")
                            if row.get('elements_cv'):
                                st.write(f"*√âl√©ments du CV:* {row['elements_cv']}")
                            st.write(f"*Confiance:* {float(row['confiance']):.0%}")
                            st.divider()
            else:
                for _, row in df.iterrows():
                    status_emoji = {"CONFORME": "‚úÖ", "A CHALLENGER": "‚ö†Ô∏è", "NON CONFORME": "‚ùå"}
                    emoji = status_emoji.get(row["statut"], "‚ùì")
                    st.write(f"{emoji} **{row['exigence_titre']}**")
                    st.write(f"*Justification:* {row['justification']}")
                    if row.get('elements_cv'):
                        st.write(f"*√âl√©ments du CV:* {row['elements_cv']}")
                    st.write(f"*Confiance:* {float(row['confiance']):.0%}")
                    st.divider()

        export_df = pd.DataFrame(details_export)
        csv = export_df.to_csv(index=False, encoding="utf-8")
        st.download_button(label="üíæ T√©l√©charger CSV", data=csv, file_name=f"analyse_cv_gfsi_{datetime.now().strftime('%Y%m%d_%H%M')}.csv", mime="text/csv")

with st.expander("üìö Structure du r√©f√©rentiel JSON"):
    st.code("""
{
  "metadata": {"name": "Nom du r√©f√©rentiel","version": "1.0","description": "Description","date_creation": "2024-01-01"},
  "categories": {"formation": {"name": "Formation","weight": 0.3,"description": "Texte"}},
  "exigences": {
    "FORM_001": {
      "id": "FORM_001","category": "formation","title": "Titre",
      "description": "D√©tail","criteres": ["Crit√®re 1"],"exemples_conformes": ["Exemple"],
      "exemples_non_conformes": ["Contre-exemple"],"niveau_requis": "obligatoire|recommande|souhaitable","ponderation": 1.0
    }
  }
}
""", language="json")
