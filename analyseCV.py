# Analyse de CV GFSI avec jauges et JSON tolÃ©rant
import streamlit as st
import PyPDF2
import json
from datetime import datetime
from pathlib import Path
import groq
import pandas as pd
import plotly.graph_objects as go

st.set_page_config(page_title="Analyse de CV GFSI", layout="wide")
st.title("ğŸ“„ Analyse comparative de CV - Auditeurs GFSI")

def afficher_jauge(titre, valeur):
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=valeur * 100,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': titre},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'color': "green" if valeur >= 0.75 else "orange" if valeur >= 0.5 else "red"},
            'steps': [
                {'range': [0, 50], 'color': "#f8d7da"},
                {'range': [50, 75], 'color': "#fff3cd"},
                {'range': [75, 100], 'color': "#d4edda"}
            ]
        }
    ))
    st.plotly_chart(fig, use_container_width=True)

def extract_valid_json(text):
    decoder = json.JSONDecoder()
    text = text.strip()
    for i in range(len(text)):
        try:
            obj, _ = decoder.raw_decode(text[i:])
            return obj
        except json.JSONDecodeError:
            continue
    return None

# Sidebar config
with st.sidebar:
    st.header("ğŸ”§ Configuration")
    api_key = st.text_input("ğŸ”‘ ClÃ© API Groq :", type="password")
    if not api_key:
        st.warning("Veuillez saisir une clÃ© API valide.")
        st.stop()

    client = groq.Client(api_key=api_key)

    @st.cache_data
    def load_referentials():
        referentials = {}
        ref_dir = Path("referentiels")
        if ref_dir.exists():
            for file in ref_dir.glob("*.json"):
                with open(file, encoding="utf-8") as f:
                    referentials[file.stem] = json.load(f)
        return referentials

    referentials = load_referentials()
    if not referentials:
        st.error("Aucun rÃ©fÃ©rentiel trouvÃ©.")
        st.stop()

    ref_name = st.selectbox("ğŸ“š RÃ©fÃ©rentiel GFSI :", list(referentials.keys()))
    selected_ref = referentials[ref_name]

    model = st.selectbox("ğŸ§  ModÃ¨le IA :", [
        "meta-llama/llama-4-maverick-17b-128e-instruct", "llama-3.3-70b-versatile", "openai/gpt-oss-120b", "moonshotai/kimi-k2-instruct-0905", "qwen3-72b"
    ])

# Fichiers PDF
uploaded_files = st.file_uploader("ğŸ“„ Chargez un ou plusieurs CV (PDF uniquement)", type=["pdf"], accept_multiple_files=True)

if uploaded_files and st.button("ğŸ” Lancer l'analyse IA"):
    results_all = []
    details_export = []

    with st.spinner("Analyse des CV en cours..."):
        for uploaded_file in uploaded_files:
            try:
                uploaded_file.seek(0)
                reader = PyPDF2.PdfReader(uploaded_file)
                cv_text = " ".join([page.extract_text() or "" for page in reader.pages])

                prompt = f"""
Tu es un expert en conformitÃ© GFSI.
Analyse le CV ci-dessous en comparant CHAQUE EXIGENCE du rÃ©fÃ©rentiel une par une.
Pour chaque exigence :
- indique si elle est âœ… CONFORME, âš ï¸ Ã€ CHALLENGER, ou âŒ NON CONFORME
- fournis une justification brÃ¨ve basÃ©e sur les donnÃ©es du CV
- indique un score de confiance (0 Ã  1)

RÃ‰FÃ‰RENTIEL GFSI :
{json.dumps(selected_ref, indent=2)}

CV DU CANDIDAT :
{cv_text}

RÃ©pond UNIQUEMENT avec un objet JSON strictement valide :
{{
  "analysis": [
    {{
      "exigence": "description de l'exigence",
      "statut": "CONFORME / Ã€ CHALLENGER / NON CONFORME",
      "justification": "justification basÃ©e sur le CV",
      "confiance": 0.85
    }}
  ],
  "synthese": "rÃ©sumÃ© clair et actionnable pour le candidat"
}}
"""

                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1
                )

                result = response.choices[0].message.content.strip()
                result_data = extract_valid_json(result)
                if not result_data:
                    st.error(f"âš ï¸ JSON invalide pour {uploaded_file.name}")
                    continue

                analysis = result_data.get("analysis", [])
                for a in analysis:
                    a["cv"] = uploaded_file.name
                    details_export.append(a)

                conformes = sum(1 for i in analysis if i.get("statut", "").upper() == "CONFORME")
                challengers = sum(1 for i in analysis if "CHALLENGER" in i.get("statut", "").upper())
                non_conformes = sum(1 for i in analysis if i.get("statut", "").upper() == "NON CONFORME")
                score_moyen = round(sum(i.get("confiance", 0) for i in analysis) / len(analysis), 2) if analysis else 0

                results_all.append({
                    "nom": uploaded_file.name,
                    "conformes": conformes,
                    "challengers": challengers,
                    "non_conformes": non_conformes,
                    "score": score_moyen,
                    "details": analysis,
                    "synthese": result_data.get("synthese", "")
                })

            except Exception as e:
                st.error(f"âŒ Erreur pour {uploaded_file.name} : {e}")

    # Affichage des rÃ©sultats
    for result in results_all:
        st.subheader(f"ğŸ“„ RÃ©sultats pour : {result['nom']}")
        df = pd.DataFrame(result["details"])

        st.markdown("### ğŸ¯ Taux de conformitÃ© par exigence")
        grouped = df.groupby("exigence")
        for exigence, group in grouped:
            total = len(group)
            conformes = group["statut"].str.upper().eq("CONFORME").sum()
            taux_conformite = conformes / total if total > 0 else 0
            afficher_jauge(exigence, taux_conformite)

        st.markdown("### ğŸ§  SynthÃ¨se IA")
        st.info(result["synthese"])
